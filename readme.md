The SpeechCommands Dataset is an audio dataset of spoken words designed to help train and evaluate keyword spotting systems. Here, we use Pytorch to develop a model for Audio Classification using CNN. CNN are the most poplar architectures for classifying images... But we have speech right ?! We will use TorchAudio to extract Spectrograms (images) from commands (speech) and feed them to the neural network. We built a computer vision able to understand "yes" or "no" speech and achieved an accuracy of 93%, which impressive!